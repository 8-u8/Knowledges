# 7章
## この章が僕たちにもたらしてくれるもの

データ点$x_0$が与えられたときの$Y$についてのモデル$Y = f(X) + \epsilon$の誤差の条件付き期待値は「バイアス」と「分散」に分解ができる。

$$E(Loss(Y, \hat{f}(X))|X=x_0)=\sigma_{\epsilon_0} + Bias(Y,\hat{f_{x_0}}(X)) + Var(\hat{f}_{x_0}(X))$$

ここで$\sigma_{\epsilon_0}$は誤差項の分散(どうしようもないもの)、  
$Bias$は、モデルと真の値との乖離、
$Var$は、モデルにおける予測値の分散を意味する。

一般に、モデルが複雑になると、バイアスは強くなり、予測値の分散は小さくなる。
というか、バイアスが強くなると、予測値の分散は小さくなる。逆もまた然り。

このバランスを取るための方法にはAICとかBICとかによる「推定」と、交差検証やブートストラップなどによって直接的に推計しようというのがある。  
AICやBICがどうやってこのバイアス・バリアンスを評価しようとしているかをのべて、その後交差検証・ブートストラップを述べていく。

気をつけるべきはここ

## 伊藤のフォーカスするところ
統計モデリング的にはAICやBICといった情報量規準が広く知られているが、機械学習的なトピックとしては交差検証やブートストラップによる評価が一般的になってきているので、比重としてはこちらを頑張ることにする。  
頑張って理屈と実運用上のいろいろとバランスよくしたい。  
カステラ本にもあるが、これらの比較はある程度連動する。

## 参考文献
機械学習におけるモデル評価については「kaggle本」も知られている。  
これは「バイアスなく、いい精度を出す」ということに特化したコンペ勢の頑張りが入っているのであった。  
カステラ本は相対的に古い(が、こうしたモデル評価の基本的考え方についてはそうそう時間が影響することはない)ので、これらの情報も適宜引用しつつそれっぽくまとめていく。

- Kaggleで勝つデータ分析の技術(技術評論社)

## 7.1 導入
- 汎化性能を高めることがモデルの性能を左右するので見ていこう。

## 7.2 バイアス, 分散, モデル複雑度
### 訓練誤差とテスト誤差(汎化誤差)
- 訓練誤差: 学習データにおける誤差
- 汎化誤差: 学習データと独立に同じ母集団からサンプルしたデータに対しての誤差
- 期待予測誤差: 訓練誤差関数の実現値の期待値
  - 同じ分布から独立にサンプルしているなら、誤差関数の実現値の期待値は  
  訓練誤差と汎化誤差で近似するはず
  - 期待値は一応不偏推定量なので。
- 実際はそういうことはない
  - 汎化誤差は訓練誤差より大きくなりがち
  - モデルの複雑度というパラメータが絡むため。
- モデル複雑度が高まる(説明変数を増やすとか)
  - 訓練誤差が小さくなるが汎化誤差が大きくなる(過学習)
  - つらい
### 誤差の評価でできること
- モデルの選択
  - どのモデルが最も汎化性能が高いと言えそうかを考えられる
- モデルの評価
  - 選択したモデルがテストデータにおいてどれだけの誤差で予測を当てられるかを推定できる
### ちなみに: いろいろな誤差関数
7章では最小二乗誤差とか絶対値誤差とか対数尤度がでたが、誤差関数はいろいろある。  
特に決定木やブースティングなどは、誤差関数をいろいろと選ぶことができる。  
普通にいえばどの誤差関数を使っても大体最小化は進むが、7.3節に在るようにトレードオフの挙動は微妙に変化する。    
タスクに応じて使い分けることで、汎化誤差の推定をより正確に推定しよう。

#### 数値予測
- RMSE(最小二乗誤差の2乗根)
  - 外れ値に弱い
- RMSLE(対数最小二乗誤差の2乗根)
  - 外れ値にも強くなる。

#### 二値分類
基本的には流派は2つ。混同行列から比率を計算するか、予測値を確率とみて評価するか
- 混同行列
  - Accuracy
  - F1-Score/F-$\beta$Score
  - MCC
    - 不均衡データにもつよい
- 確率値
  - logloss
  - AUC
  - 不均衡データに対応するために重み付けなどする流儀もある。
  
#### 多値分類
- 基本的には二値分類の一般化によって得られる
  - multiclass accuracy
  - multiclass F1-Score
  - multiclass logloss
- 順序つき変数に対してはQWK(Quadratic Weighted Kappa)とかがある
  - $\kappa = 1-\frac{\sum_{i,j}{w_{i,j}O_{i,j}}}{\sum_{i,j}{w_{i,j}E_{i,j}}}$
  - $O_{i,j}$: 実際はクラス$i$だけど$j$と予測した数
  - $E_{i,j}$: 真のクラスと予測クラスの分布が独立の場合の混同行列の$(i,j)$要素の期待度数
  - $w_{i,j}$:クラス$i$とクラス$j$との差の2乗。
  - QWKはマルチクラス版RMSE的な感じがある
    - アンケートとかの意識と実際の購買行動とのズレとかにも使える
    - あるいは自己評価と他者評価のズレ度とかにも使える
  
## 7.3 バイアス-分散分解
- いいたいことは最初に言ってしまった。つまり、誤差関数の期待値は
  - 真の値の分散(どうしようもないもの)
  - 真の値と予測値とのズレ(バイアス)
  - 予測値の分散(バリアンス)
- に分かれる。
- 往々にしてバイアスとバリアンスはトレードオフ関係にある。
### OLSの例
- OLSの推定値は不偏性を持つ。
  - つまりちゃんとやれば推定値のバイアスは0。
  - パラメータ数が多くなると分散が大きくなる。
- Ridgeになるともうちょっと豊かになる。
  - $\hat{f}(x_0) = x_0^T(\bold{X}^T\bold{X}+\alpha\bold{I})^{-1}\bold{X}^Ty$
  - $\alpha$は2章・3章であった$\lambda$と同じ
  - $\alpha$が大きくなるとバイアスが大きくなり、分散が小さくなる
    - 逆に小さくなるとバイアスが小さくなり、分散が大きくなる
- 図7.2がすべて。
### トレードオフ
- 例示です。
- 「バイアスとバリアンスのトレードオフは誤差関数によってもモデル複雑度に寄っても違う」
## 7.4 訓練誤差の<s>最善</s>楽観度
- 誤分類率: 何が固定で何が固定じゃないのか微妙なのでいくつか定義する

#### モデル$\hat{f}$の汎化誤差
訓練集合$\Tau = \{(x_0, y_0),(x_1,y_1),...,(x_N,y_N)\}$が与えられたときのモデルの汎化誤差は以下。
$$Err_\Tau = E_{X_0, Y_0}[L(Y^0, \hat{f}(X^0))|\Tau]$$
- $(X_0, Y_0)$は訓練集合と同じ母集団から得られた新しいデータ点。  
  - 学習データで学習したという条件で、新しいデータに対する誤差の期待値。  
  - あとで「真の誤差」とも言いかえられている。
  - $\Tau$の周りで平均すると式7.16となる。曰く「扱いやすい」らしい。  
    - 詳しい話は7.12節まで待つことになる。

#### モデル$\hat{f}$の訓練誤差
モデル学習時に計算される誤差を訓練誤差という。

$$\bar{err} = \frac{1}{N}\sum_{i=1}^NL(y_i, \hat{f}(x_i))$$

- 基本的に訓練誤差でモデルが改善しているかを評価し、訓練誤差を小さくするように学習が進む
  - 当たり前のように$Err_\Tau$より小さくなる傾向がある。

#### 訓練標本内誤差と訓練標本外誤差
- 訓練標本**外**誤差
  - テスト集合から得られた誤差。
  - 訓練標本にないデータで得られる
- 訓練標本**内**誤差
  - $Err_{in} =  \frac{1}{N}\sum_{i=1}^NE_{Y^0}[L(Y_i^0, \hat{f}(x_i))|\Tau]$
  - 訓練標本で使った入力による新しい出力$Y^0$を使った誤差。
  - 社会科学ではあまり想定しづらいが、同じ量、同じ温度のお湯が蒸発するまでの時間とかそういうのだと想像しやすい気がしている。
  - 再現された反応に対する誤差。
- <s>最善</s>楽観度
  - $op \equiv Err_{in} - \bar{err}$
  - 訓練誤差の改善度合いは、訓練誤差と訓練データを使った別の反応に対する誤差との差で決まる
  - これも期待値をとる$\omega = E_y(op)$
- <s>最善</s>楽観度の期待値は推定値$\hat{y}$と真値$y$の共分散の平均っぽいやつになるらしい
  - $\frac{2}{N}\sum_{i=1}^NCov(\hat{y_i},y_i)$
  - 誤解を恐れずにいえば、予測値と真値の相関が<s>最善</s>楽観度を左右する。
- <s>最善</s>楽観度について「まとめる」と7.22式(なんか重要らしい)
  - 訓練標本内誤差の期待値は、訓練誤差の期待値と<s>最善</s>楽観度の期待値で計算できるらしい
  - $err$はわかるので、<s>最善</s>楽観度を**推定**したい。
    - つまりは訓練標本外誤差の**期待値**
    - なぜなら訓練内標本誤差は新たな反応がないと計算できないので
  - AICとかはこっち
    - 線形モデルである必要がある
- 訓練外標本誤差を直接推定したい！
  - 訓練集合を細切れにすればいいんじゃない？
  - 訓練集合から訓練部分集合をサンプリングしてやればいいんじゃない？
  - こっちはいろんなモデルで実行できる。

## 7.5 訓練標本<s>外</s>**内**誤差の推定
#### $C_p$ Statistics とAIC
- $C_p$統計量
  - 訓練誤差に$2\frac{d}{N}\hat{\sigma_\epsilon^2}$を加える
  - 誤差項の分散と説明変数の数とデータ数の比
    - 訓練誤差は説明変数が増えるほど小さくなりがちなので、説明変数の数を罰則定数にすることで補正をかけているというワケ。
- AIC(Akaike Infomation Criterion)
  - 赤池情報量**規準**。間違えたら泣く。
  - 最尤推定版$C_p$(ざっくり)
  - 定義式はみんな大好き$-\frac{2}{N}loglik+ 2\frac{d}{N}$
    - $loglik$は対数尤度関数の最大値$\sum_i^N{\log{Pr_{\hat{\theta}}(y_i)}}$
- 非線形の場合、複雑度パラメータを別に定義しないといけない。

#### AICの推定
- 調整パラメータ$\alpha$によって指定されるモデル集合$f_\alpha(x)$
  - ここでいうモデル集合は、モデル$f(x)$をその構造を変えないままちょっとどっか変わったモデル
  - 訓練誤差やパラメータ数も$\alpha$についての関数として定義される。
  - 誤差項の情報は$\alpha$に依存しない。どうしようもないものなので。
  - $AIC(\alpha) = \hat{err}(\alpha) + \frac{2d(\alpha)}{N}\hat{\sigma}_\epsilon^2$を最小化するような$\hat{\alpha}$を探す旅
    - 有効パラメータ数はちょっと次まで待ってください。
    - とりあえず適応的な選び方をするとせっかくの<s>最善</s>楽観度が信頼できなくなるらしい。
- AICは最適な<s>規定</s>基底関数の数を選べる。
  - 加法的な誤差関数(MAEとか)に対して簡単な公式が厳密に成り立つ  
  - 最尤推定でも近似的に成り立つ。すごい。
  - 当たりか外れかみたいな誤差関数でもまあまあ使われるらしい
    - そもそも0/1損失をあまり使わなくなった件。

## 7.6 有効パラメータ数
- 数理統計学チックな話。
  - $\bold{\hat{y}} = \bold{S}\bold{y}$
  - $\bold{S}$は<s>説明変数と相関しても目的変数に相関しない</s>謎のN次正方行列
    - 線形回帰のパラメータ推定値から$\bold{y}$をぬいたものと同じやつ。
    - 「予測値とは目的変数に$x$による演算$\bold{S}$をかませた結果得られる」と考える
  - 有効なパラメータ数は$trace(\bold{S})$で決まるっぽい
    - $M$個の説明変数によって表現される空間の直行射影空間であれば有効なパラメータ数は$M$である
    - この辺はおそらく線形代数学べば割とすんなり行ける。
    - [ここの補題6とかドンピシャなので読もう](http://www.stat.t.u-tokyo.ac.jp/~sei/lec/AS_19_03_hosoku.pdf)
  - ニューラルネットワークのときはヘッセ行列とか使ってやるらしい
    - ちょっとよくわかんねえので議論する場合は議論する。
    - 活性化関数に関係しそうだが……

## 7.7 ベイズ法とベイズ情報量規準
- 最尤推定で使える。公式は7.35式。
  - シュワルツ規準とも。
- AICよりもBICのほうが複雑度に対して厳しい。
- ベイズっぽい考え方でモデルを選ぶのでAICとは「動機づけ」が違う
  - モデルの比較にベイズ推定を使う
  - 訓練データが与えられた時、モデル$M_m$が「良いモデル」である確率の比(ベイズ因子)
  - ラプラス近似とかするとBICになる(7.40)
  - 一番いいモデルを選べるけど、モデルのランキングも作れる
  - 漸近一致性を持つ(最尤推定なので)
    - Nが無限にとべば「正しいモデル」を選ぶことができる
    - つまり平均<s>最善</s>楽観度の大きいモデル。
- AICもBICもどっちも長所短所がある
  - AICは複雑なモデルを選びがち
  - BICは簡単なモデルを選びがち

## 7.8 最小記述長
## 7.9 バプニックーチェルポネンキス次元
- これらは現状あまり広く用いられていない
- 加えてこのあたりをうまく議論するには計算機科学のちょっと深めの知識がいる
- 一旦交差検証に進み、要あらば戻ります。

ここから先は次回です。
### WAICとか他のAICっぽいものについて
#### WAIC(Widely applicable information criterion)
- [「広く使える情報量規準」](http://www.jmlr.org/papers/volume11/watanabe10a/watanabe10a.pdf)
- 「渡辺ベイズ」の渡辺澄夫先生が開発した。
  - [簡単な説明](http://watanabe-www.math.dis.titech.ac.jp/users/swatanab/waic2011.html)
  - WAICのWはWatanabeではない(衝撃の事実)
  - $WAIC = -2(\sum_{i=1}^{N}Pr(y_i) - \sum_{i=1}^{N}Var(y_i))$
    - $Pr(y_i)$: 観測値$i$の事後分布から得られる対数尤度平均
    - $Var(y_i)$: 同上における分散
- 何故「広く使える」のか？
  - **「真のモデル」を仮定しなくていい。**
    - ここまでの議論: 真のモデルと手元のモデルのズレを評価したかった
    - [MCMCでのサンプリングで評価できちゃう](http://ushi-goroshi.hatenablog.com/entry/2017/12/24/225748)
    - モデルから得られてい対数尤度の平均と分散で評価しているので。
  - <s>え、じゃあ上の議論はどうなるんだ</s>

## 7.10 交差確認
### いろんなfoldの区切り方
kaggle本では状況に応じていろいろなfoldの切り方を紹介している。
カステラ本ではスタンダードな`Kfold`を紹介しているが、他にもいろいろある。  
お好みに合わせてお使いください。  
[scikit-learnライブラリ](https://scikit-learn.org/stable/auto_examples/model_selection/plot_cv_indices.html#sphx-glr-auto-examples-model-selection-plot-cv-indices-py)では具体的なCross Validationのデータの分割のされ方について議論されています。  
ここでは「Shuffle」の概念は一回考えません。

#### train test split
- 超基本。
- 学習データを2分割する。
  - 大体4:1くらいが多い
  - 4で学習、1で検証。
- hold out validationとも言う。

#### KFold
- 超基本。その2。
  - train-test splitを繰り返す
- 学習データをK分割する。
  - K-1個を学習に、残りの1個を検証に用いる。
  - それを全部の分割が1回検証に用いられるように繰り返す。
- 十分なデータ量がある(前提)
  - ないとあまり効果がない。
- 最適なKって？
  - 理屈はあまりない
  - K=N(データ量)の場合、クロスバリデーションによる平均誤差推定値は不偏。
  - でもあまりやらない。
  - データ数にも夜が大体5〜10くらい。
- 弱点: データに規則性がある場合は使えない

#### Stratified Kfold
- 層化K分割
  - データが何かのクラスに分かれている時に用いるKFold
  - クラス別に同じ比率で分割する
- 例: 地方を伴うアンケート分析
  - 地方別に一定割合でサンプリングしたバリデーションセットができないと、  
  　例えば東京都に最適化されたモデルができてしまう。
  - Stratified KFoldであんしん！

#### Group Kfold
- なんかのグループ別にKFold
- 例: 購買のログデータなど「個人の行動が複数行記録される」みたいなデータの予測の場合
  - 個人の行動の中からランダムに持ってきてバリデーションを作らないと、  
　  特定の属性に対して過剰にフィットするモデルができてしまう。
  - Group KFoldであんしん！

#### TimeSeriesSplit
- 時系列ごとにSplitする
- 例: 売上予測など(MMM的なアプローチ)
  - 普通のKFoldはデータの時系列性を気にしないでランダムにとってくる
  - 「未来のデータ」で学習し「過去」を評価するなど、ちょっとヤバイことも平気でやってくれる

#### Adversarial Validation(応用)
- [kaggleで使われた手法](https://www.kaggle.com/c/home-credit-default-risk/discussion/64722)
  - TrainとTestをがっちゃんこする。
  - TrainとTestを分類するモデルを作る。
  - Testと予測値が近いTrainをValidationに用いる
- TrainとTestの分布が違う、みたいな場合に  
「Testに近いTrainを優先的にValidationにしよう」というモチベーション。
- Testセットに近いTrainデータを持ってくるので、  
kaggleのように「testがわからない」みたいな場合に有効。
- 傾向スコアマッチングとアイデアは近い。
  - 実際、Adversarial Validationの要領で「TrainとTestを分けるのに重要な特徴量」を削除して  
  　Trainデータへの過学習を抑制する、という使い方もある

### いくつぐらいがいいの？
- テスト集合の誤差の分散を小さく、かつバイアスを小さくしたいワケ
  - でもこれは上記の議論の通り簡単には実現しない
  - 分割数が少ない→バイアスが大きい→バイアスが大きい/分散は小さい
  - Leave one out(データ数分KFoldする)→バイアスが小さい/分散はでかい
- 実務的には大体5〜10
  - 増やしすぎてもあまり意味はない

### 7.10.2 交差確認を実行する正しい方法と間違った方法
- 要はLabel Encodingに近い。
  - 目的変数を基準にして特徴量を作ること。
  - 手法としてはあるがLeakageのもとになるので注意すべし
- Foldを切る→学習をするの順序は守られなければならない。
  - モデリングしてからFold切っても意味がない。

### 7.10.3 交差確認は本当に有効？
- 上手くやれば有効(あたりまえ)

## 7.11 ブートストラップ法
- Trainから復元抽出で擬似的にデータを構成する方法。
  - データを分割するのではなく、データを作って評価する方法
  - そう考えると交差確認とはまた違う……
- ブートストラップした標本をバリデーションに使えば良いのでは？
  - ダメ
  - Trainに含まれる情報を復元抽出して構成するので
  - それを外してやればまあまあ。

### テスト誤差を推定する方法
- 交差確認はどちらかと言えば「条件付きのテスト誤差の期待値」みたいなものを計算する
- ブートストラップ法では、データを擬似的に生成するので、テスト誤差の推定ができる。
  - ただ、訓練データに含まれる要素も使うので、その補正が必要($\hat{R}$がその指標)
  - 
## 7.12 条件付きテスト誤差か期待テスト誤差か
A. 場合による  
上手く設計すれば、どちらでも汎化誤差の期待値っぽい値は得られる。  

### 実際どうなん？
- 正直ブートストラップ法によるモデル評価は、kaggleとかでもあまり行わない印象。
  - シミュレーションでは使うかもしれない
  - あとデータが少ないときとかは使うかもしれない
- 理由は謎だが、おそらく交差確認の仕方がデータの性質に対応できるように多様化しているため。
  - データの規則性とかクラス・時系列性などに対応したデータの分割は簡単
  - これらに対応したデータの「生成・サンプリング」は難しい？

### 具体的な方法は……？
個人的にはLeakしないValidation設計が重要だと思うので、7.10で語った話が必要になりそうだなと思う。
